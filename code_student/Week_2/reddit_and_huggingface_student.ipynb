{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align = \"center\" draggable=â€falseâ€ ><img src=\"https://user-images.githubusercontent.com/37101144/161836199-fdb0219d-0361-4988-bf26-48b0fad160a3.png\" \n",
    "     width=\"200px\"\n",
    "     height=\"auto\"/>\n",
    "</p>\n",
    "\n",
    "# Reddit and HuggingFace Starter Kit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: [Reddit API](https://www.reddit.com/dev/api/)\n",
    "The first part of this excercise is to figure out how to instantiate a Reddit API object using the Python Reddit API Wrapper [PRAW](https://praw.readthedocs.io/en/stable/).  PRAW is a Python library that provides a simple interfaceto interact with the Reddit API.\n",
    "\n",
    "### Your Task\n",
    "You will first need to instantiate a [Reddit instance](https://praw.readthedocs.io/en/stable/code_overview/reddit_instance.html).\n",
    "Hint: you only need to use `client_id`, `client_secret`, and `user_agent`\n",
    "\n",
    "#### Make sure everyone in the group does this part! \n",
    "\n",
    "Follow the guide below on how to get your `client_id` and `client_secret`.\n",
    "\n",
    "#### Follow these steps:\n",
    "1. Pull the `FourthBrain/ML03` repo locally so you can start development.\n",
    "2. Open `reddit_and_huggingface.ipynb` and install the necessary packages for this lesson by running:\n",
    "\n",
    "    ```\n",
    "    cd code_student/Week_2\n",
    "    conda activate {your_virtual_environment_name}\n",
    "    pip install transformers praw torch torchvision torchaudio\n",
    "    ```\n",
    "    \n",
    "3. Obtain your `client_id` and `client_secret`\n",
    "\n",
    "* Make a Reddit account\n",
    "* Follow the steps in this screenshot which are the first steps from this [guide](https://towardsdatascience.com/how-to-use-the-reddit-api-in-python-5e05ddfd1e5c).\n",
    "\n",
    "![instructions to set up reddit api](../../images/reddit_get_access.JPG)\n",
    "\n",
    "* Create a `secrets.py` file and include the following:\n",
    "\n",
    "    ```\n",
    "    REDDIT_API_CLIENT_ID = \"\"\n",
    "    REDDIT_API_CLIENT_SECRET = \"\"\n",
    "    REDDIT_API_USER_AGENT = {can_be_any_string...for ex: \"teslabot\"}\n",
    "    ```\n",
    "    Get it?  [Teslabot :)](https://www.tesla.com/AIhttps://www.tesla.com/AI)\n",
    "    \n",
    "\n",
    "* Put `secrets.py` in `Week_2` so you can easily import it\n",
    "\n",
    "4. Complete the code in the `# YOUR CODE HERE` space below that creates a reddit instance object that allows us to interact with the Reddit API.  Note that the `subreddit` object for the 'r/TSLA' subreddit has already been created for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d624cbe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from transformers import pipeline\n",
    "import secrets\n",
    "\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=secrets.REDDIT_API_CLIENT_ID,\n",
    "    client_secret=secrets.REDDIT_API_CLIENT_SECRET,\n",
    "    user_agent=secrets.REDDIT_API_USER_AGENT\n",
    ")\n",
    "\n",
    "subreddit = reddit.subreddit('TSLA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II:  [r/TSLA Subreddit](https://www.reddit.com/r/TSLA/)\n",
    "The second part of this exercise is to figure out how to the following code is parsing comments through use of the r/TSLA `subreddit` instance object.\n",
    "\n",
    "### Your Task\n",
    "1. Work with your group to comment each line of the following code so that you describe what each piece is doing.\n",
    "2. Create one comment at the top of the code that describes what the larger for loop is iterating over.  \n",
    "3. (Optional) How many comments will I get from this?\n",
    "\n",
    "A few resources that might help!\n",
    "* How do I find the top 10 posts of all time from your favorite subreddit(s)? (hint: look at [\"Obtain Submission Instances from a Subreddit\"](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html))\n",
    "* How do I parse comments from the post? (hint: look at [\"Obtain Submission Instances from a Subreddit\"](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from praw.models import MoreComments\n",
    "\n",
    "top_comments = []\n",
    "\n",
    "# iterates over the top subreddit submissions, limited in amount by the \"limit param\"\n",
    "for submission in subreddit.top(limit=10):\n",
    "    # iterates over the submissions obtained\n",
    "    for top_level_comment in submission.comments:\n",
    "        # if the comment still has more comments inside (represented by obj MoreComments) go to the next comment\n",
    "        if isinstance(top_level_comment, MoreComments):\n",
    "            continue\n",
    "\n",
    "        # if is here it has no comments it is a top level comment and is attached a the output list\n",
    "        top_comments.append(top_level_comment.body)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79ff4596",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = top_comments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e253c175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ho lee fuk \\n\\nyou got anymore insider information? ðŸ‘€ðŸ‘€'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III:  [HuggingFace](https://huggingface.co/docs/transformers/quicktour)\n",
    "The third part of this exercise is to analyze the sentiment of each comment scraped from `r/TSLA` to using a pre-trained HuggingFace model to make the inference. \n",
    "\n",
    "### Your Task\n",
    "1. Implement the [Sentiment Analysis](https://huggingface.co/docs/transformers/quicktour) Model in the `# YOUR CODE HERE` section. \n",
    "2. (Optional) What is the net sentiment of the entire list of comments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment_model = pipeline(\"sentiment-analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment test: Would be great but Elon said he wasn't in a hurry to do that again === [{'label': 'NEGATIVE', 'score': 0.9818630814552307}]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def get_random_comment(conversations):\n",
    "    comment = random.choice(conversations)\n",
    "    return comment\n",
    "\n",
    "# Run sentiment analysis\n",
    "sentiment_query_sentence = get_random_comment(top_comments) # grabs a random comment from the comment and replies list\n",
    "sentiment = sentiment_model(sentiment_query_sentence) # \n",
    "print(f\"Sentiment test: {sentiment_query_sentence} === {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3e14536",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_all = sentiment_model(top_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7fe8475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b3b7bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(sentiment_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69f617d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.993740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.995970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.992491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.997287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label     score\n",
       "0  NEGATIVE  0.993740\n",
       "1  NEGATIVE  0.999329\n",
       "2  NEGATIVE  0.995970\n",
       "3  NEGATIVE  0.992491\n",
       "4  NEGATIVE  0.997287"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c89119c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEGATIVE    106\n",
       "POSITIVE     61\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7b00ec7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEGATIVE    0.634731\n",
       "POSITIVE    0.365269\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts() /df.label.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604db50e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
